import subprocess
import threading
import time
import re
import os
from dataclasses import dataclass
from typing import Dict, List, Optional
from queue import Queue

@dataclass
class PgbenchConfig:
    """pgbench ÈÖçÁΩÆÁ±ª"""
    # pgbench Âü∫Á°ÄÈÖçÁΩÆ
    clients: int = 10           # Âπ∂ÂèëÂÆ¢Êà∑Á´ØÊï∞
    jobs: int = 2              # Â∑•‰ΩúÁ∫øÁ®ãÊï∞
    duration: int = 300        # ÊµãËØïÊó∂ÈïøÔºàÁßíÔºâ
    scale_factor: int = 10     # Êï∞ÊçÆËßÑÊ®°Âõ†Â≠ê
    
    # ÊµãËØïÊ®°Âºè
    mode: str = "tpc-b"        # tpc-b, read-only, custom
    custom_script: Optional[str] = None
    
    # Êä•ÂëäÈÖçÁΩÆ
    progress_interval: int = 5  # ËøõÂ∫¶Êä•ÂëäÈó¥Èöî
    warmup_time: int = 60      # È¢ÑÁÉ≠Êó∂Èó¥
    
    # Êï∞ÊçÆÂ∫ìËøûÊé•ÈÖçÁΩÆ
    connections: Dict = None   # {'direct': {...}, 'proxy': {...}}

class PgbenchLoadGenerator:
    """pgbench Ë¥üËΩΩÁîüÊàêÂô®"""
    
    def __init__(self, config: PgbenchConfig):
        self.config = config
        self.processes = {}  # {conn_type: process}
        self.metrics_queue = Queue()
        self.running = False
        self.start_time = None
        self.metrics = {
            'direct': {'tps': [], 'latency': [], 'errors': []},
            'proxy': {'tps': [], 'latency': [], 'errors': []}
        }
    
    def prepare_database(self):
        """ÂáÜÂ§á pgbench ÊµãËØïÊï∞ÊçÆ"""
        print("üîß ÂáÜÂ§á pgbench ÊµãËØïÊï∞ÊçÆ...")
        
        for conn_type, conn_config in self.config.connections.items():
            print(f"   ÂàùÂßãÂåñ {conn_type} ËøûÊé•ÁöÑÊµãËØïÊï∞ÊçÆ...")
            
            cmd = [
                'pgbench',
                '-i',  # ÂàùÂßãÂåñÊ®°Âºè
                '-s', str(self.config.scale_factor),
                '-h', conn_config['host'],
                '-p', str(conn_config['port']),
                '-U', conn_config['user'],
                '-d', conn_config['database']
            ]
            
            # ËÆæÁΩÆÁéØÂ¢ÉÂèòÈáèÔºàÂ¶ÇÊûúÈúÄË¶ÅÂØÜÁ†ÅÔºâ
            env = os.environ.copy()
            if 'password' in conn_config:
                env['PGPASSWORD'] = conn_config['password']
            
            try:
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=300, env=env)
                if result.returncode == 0:
                    print(f"   ‚úÖ {conn_type} Êï∞ÊçÆÂàùÂßãÂåñÂÆåÊàê")
                else:
                    print(f"   ‚ùå {conn_type} Êï∞ÊçÆÂàùÂßãÂåñÂ§±Ë¥•: {result.stderr}")
                    raise Exception(f"Êï∞ÊçÆÂàùÂßãÂåñÂ§±Ë¥•: {result.stderr}")
            except subprocess.TimeoutExpired:
                print(f"   ‚è∞ {conn_type} Êï∞ÊçÆÂàùÂßãÂåñË∂ÖÊó∂")
                raise Exception("Êï∞ÊçÆÂàùÂßãÂåñË∂ÖÊó∂")
    
    def start_load_generation(self):
        """ÂêØÂä®Ë¥üËΩΩÁîüÊàê"""
        print("üöÄ ÂêØÂä® pgbench Ë¥üËΩΩÁîüÊàê...")
        self.running = True
        self.start_time = time.time()
        
        # ‰∏∫ÊØèÁßçËøûÊé•Á±ªÂûãÂêØÂä® pgbench ËøõÁ®ã
        for conn_type, conn_config in self.config.connections.items():
            process = self._start_pgbench_process(conn_type, conn_config)
            self.processes[conn_type] = process
            
            # ÂêØÂä®ËæìÂá∫Ëß£ÊûêÁ∫øÁ®ã
            parser_thread = threading.Thread(
                target=self._parse_pgbench_output,
                args=(process, conn_type)
            )
            parser_thread.daemon = True
            parser_thread.start()
        
        print(f"‚úÖ Â∑≤ÂêØÂä® {len(self.processes)} ‰∏™ pgbench ËøõÁ®ã")
    
    def _start_pgbench_process(self, conn_type: str, conn_config: Dict):
        """ÂêØÂä®Âçï‰∏™ pgbench ËøõÁ®ã"""
        cmd = [
            'pgbench',
            '-c', str(self.config.clients),
            '-j', str(self.config.jobs),
            '-T', str(self.config.duration),
            '-P', str(self.config.progress_interval),
            '-h', conn_config['host'],
            '-p', str(conn_config['port']),
            '-U', conn_config['user'],
            '-d', conn_config['database']
        ]
        
        # Ê†πÊçÆÊ®°ÂºèÊ∑ªÂä†ÂèÇÊï∞
        if self.config.mode == "read-only":
            cmd.append('-S')
        elif self.config.mode == "custom" and self.config.custom_script:
            cmd.extend(['-f', self.config.custom_script])
        
        # ËÆæÁΩÆÁéØÂ¢ÉÂèòÈáèÔºàÂ¶ÇÊûúÈúÄË¶ÅÂØÜÁ†ÅÔºâ
        env = os.environ.copy()
        if 'password' in conn_config:
            env['PGPASSWORD'] = conn_config['password']
        
        print(f"   ÂêØÂä® {conn_type} pgbench: {' '.join(cmd[:8])}...")  # Âè™ÊòæÁ§∫ÂâçÂá†‰∏™ÂèÇÊï∞
        
        return subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,  # Â∞Ü stderr ÈáçÂÆöÂêëÂà∞ stdout
            text=True,
            env=env
        )
    
    def _parse_pgbench_output(self, process, conn_type: str):
        """Ëß£Êûê pgbench ËæìÂá∫"""
        while self.running and process.poll() is None:
            line = process.stdout.readline()
            if not line:
                continue
                
            line = line.strip()
            
            # Ëß£ÊûêËøõÂ∫¶Êä•Âëä
            # Ê†ºÂºè: progress: 5.0 s, 1234.5 tps, lat 8.123 ms stddev 1.456, 0 failed
            if line.startswith('progress:'):
                metrics = self._parse_progress_line(line)
                if metrics:
                    metrics['conn_type'] = conn_type
                    metrics['timestamp'] = time.time()
                    self.metrics_queue.put(metrics)
                    
                    # Â≠òÂÇ®Âà∞ÂÜÖÂ≠ò‰∏≠Áî®‰∫éÂàÜÊûê
                    self.metrics[conn_type]['tps'].append(metrics['tps'])
                    self.metrics[conn_type]['latency'].append(metrics['latency_ms'])
            
            # Ëß£ÊûêÈîôËØØ‰ø°ÊÅØ
            elif 'ERROR' in line or 'FATAL' in line:
                error_info = {
                    'type': 'error',
                    'conn_type': conn_type,
                    'message': line,
                    'timestamp': time.time()
                }
                self.metrics_queue.put(error_info)
                self.metrics[conn_type]['errors'].append(error_info)
        
        # Ëß£ÊûêÊúÄÁªàÁªìÊûú
        if process.poll() is not None:
            # ËØªÂèñÂâ©‰ΩôÁöÑËæìÂá∫
            remaining_output = process.stdout.read()
            if remaining_output:
                self._parse_final_results(remaining_output, conn_type)
    
    def _parse_progress_line(self, line: str) -> Optional[Dict]:
        """Ëß£ÊûêËøõÂ∫¶Ë°å"""
        try:
            # ‰ΩøÁî®Ê≠£ÂàôË°®ËææÂºèËß£Êûê
            # progress: 5.0 s, 1234.5 tps, lat 8.123 ms stddev 1.456, 0 failed
            pattern = r'progress: ([\d.]+) s, ([\d.]+) tps, lat ([\d.]+) ms stddev ([\d.]+)(?:, (\d+) failed)?'
            match = re.search(pattern, line)
            
            if match:
                failed_count = int(match.group(5)) if match.group(5) else 0
                return {
                    'type': 'progress',
                    'elapsed_time': float(match.group(1)),
                    'tps': float(match.group(2)),
                    'latency_ms': float(match.group(3)),
                    'latency_stddev': float(match.group(4)),
                    'failed_count': failed_count
                }
        except Exception as e:
            print(f"Ëß£ÊûêËøõÂ∫¶Ë°åÂ§±Ë¥•: {line}, ÈîôËØØ: {e}")
        
        return None
    
    def _parse_final_results(self, output: str, conn_type: str):
        """Ëß£ÊûêÊúÄÁªàÁªìÊûú"""
        try:
            # Êü•ÊâæÊúÄÁªàÁöÑ tps ÁªìÊûúË°å
            # Ê†ºÂºè: tps = 1234.567890 (including connections establishing)
            tps_pattern = r'tps = ([\d.]+)'
            tps_match = re.search(tps_pattern, output)
            
            if tps_match:
                final_tps = float(tps_match.group(1))
                final_result = {
                    'type': 'final',
                    'conn_type': conn_type,
                    'final_tps': final_tps,
                    'timestamp': time.time()
                }
                self.metrics_queue.put(final_result)
        except Exception as e:
            print(f"Ëß£ÊûêÊúÄÁªàÁªìÊûúÂ§±Ë¥•: {e}")
    
    def stop_load_generation(self):
        """ÂÅúÊ≠¢Ë¥üËΩΩÁîüÊàê"""
        print("üõë ÂÅúÊ≠¢ pgbench Ë¥üËΩΩÁîüÊàê...")
        self.running = False
        
        for conn_type, process in self.processes.items():
            if process.poll() is None:  # ËøõÁ®ãËøòÂú®ËøêË°å
                process.terminate()
                try:
                    process.wait(timeout=10)
                    print(f"   ‚úÖ {conn_type} pgbench ËøõÁ®ãÂ∑≤ÂÅúÊ≠¢")
                except subprocess.TimeoutExpired:
                    process.kill()
                    print(f"   ‚ö†Ô∏è {conn_type} pgbench ËøõÁ®ãË¢´Âº∫Âà∂ÁªàÊ≠¢")
    
    def get_current_metrics(self) -> Dict:
        """Ëé∑ÂèñÂΩìÂâçÊÄßËÉΩÊåáÊ†á"""
        current_metrics = {}
        
        for conn_type in self.config.connections.keys():
            metrics = self.metrics[conn_type]
            if metrics['tps']:
                current_metrics[conn_type] = {
                    'avg_tps': sum(metrics['tps']) / len(metrics['tps']),
                    'max_tps': max(metrics['tps']),
                    'min_tps': min(metrics['tps']),
                    'avg_latency_ms': sum(metrics['latency']) / len(metrics['latency']),
                    'max_latency_ms': max(metrics['latency']),
                    'min_latency_ms': min(metrics['latency']),
                    'error_count': len(metrics['errors']),
                    'sample_count': len(metrics['tps'])
                }
            else:
                current_metrics[conn_type] = {
                    'avg_tps': 0,
                    'max_tps': 0,
                    'min_tps': 0,
                    'avg_latency_ms': 0,
                    'max_latency_ms': 0,
                    'min_latency_ms': 0,
                    'error_count': 0,
                    'sample_count': 0
                }
        
        return current_metrics
    
    def get_detailed_metrics(self) -> Dict:
        """Ëé∑ÂèñËØ¶ÁªÜÁöÑÊÄßËÉΩÊåáÊ†áÊï∞ÊçÆ"""
        return {
            'raw_metrics': self.metrics,
            'queue_size': self.metrics_queue.qsize(),
            'running': self.running,
            'start_time': self.start_time,
            'processes_status': {
                conn_type: process.poll() is None 
                for conn_type, process in self.processes.items()
            }
        }
