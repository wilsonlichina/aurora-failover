import threading
import time
import os
import psycopg2
from datetime import datetime, timezone
from .connection_tester import ConnectionTester, TestResult
from .pgbench_load_generator import PgbenchLoadGenerator, PgbenchConfig
from typing import Dict, List, Optional
from dataclasses import dataclass

@dataclass
class DowntimeRecord:
    """åœæœºæ—¶é—´è®°å½•"""
    connection_type: str
    start_time: datetime
    end_time: Optional[datetime] = None
    duration: Optional[float] = None
    
    def finalize(self, end_time: datetime):
        """å®Œæˆåœæœºè®°å½•"""
        self.end_time = end_time
        self.duration = (end_time - self.start_time).total_seconds()

class FailoverTester:
    """æ•…éšœè½¬ç§»æµ‹è¯•å™¨ï¼Œèƒ½å¤Ÿç²¾ç¡®ç›‘æ§æ¯ç§è¿æ¥ç±»å‹çš„downtime"""
    
    def __init__(self, config):
        self.config = config
        self.connection_testers = {}
        self.downtime_monitors = {}
        self.downtime_records = {'direct': [], 'proxy': []}
        
        # æ ¹æ®æµ‹è¯•æ¨¡å¼åˆ›å»ºç›¸åº”çš„è¿æ¥æµ‹è¯•å™¨
        if config.mode in ['direct', 'both']:
            self.connection_testers['direct'] = ConnectionTester(config, 'direct')
        if config.mode in ['proxy', 'both']:
            self.connection_testers['proxy'] = ConnectionTester(config, 'proxy')
            
        self.load_generator = PgbenchLoadGenerator(config.pgbench_config)
        self.results = {}
        self.test_running = False
        self.monitor_threads = {}
    
    def run_test(self):
        """è¿è¡Œå®Œæ•´æµ‹è¯•"""
        print("ğŸ¯ Aurora æ•…éšœè½¬ç§» + pgbench è´Ÿè½½æµ‹è¯•")
        print("=" * 60)
        
        try:
            # 1. å‡†å¤‡é˜¶æ®µ
            self._prepare_phase()
            
            # 2. é¢„çƒ­é˜¶æ®µ
            self._warmup_phase()
            
            # 3. æ­£å¼æµ‹è¯•é˜¶æ®µ
            self._main_test_phase()
            
            # 4. ç»“æœåˆ†æ
            self._analyze_results()
            
        except KeyboardInterrupt:
            print("\nâš ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
        finally:
            # æ¸…ç†èµ„æº
            self._cleanup()
    
    def _prepare_phase(self):
        """å‡†å¤‡é˜¶æ®µ"""
        print("\nğŸ“‹ å‡†å¤‡é˜¶æ®µ")
        print("-" * 20)
        
        # ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨
        os.makedirs('results', exist_ok=True)
        
        # å‡†å¤‡ pgbench æµ‹è¯•æ•°æ®
        self.load_generator.prepare_database()
        
        # éªŒè¯è¿æ¥
        print("ğŸ” éªŒè¯æ•°æ®åº“è¿æ¥...")
        self._verify_connections()
        
        print("âœ… å‡†å¤‡é˜¶æ®µå®Œæˆ")
    
    def _verify_connections(self):
        """éªŒè¯æ•°æ®åº“è¿æ¥"""
        for conn_type, conn_config in self.config.pgbench_config.connections.items():
            try:
                conn = psycopg2.connect(
                    host=conn_config['host'],
                    port=conn_config['port'],
                    user=conn_config['user'],
                    password=conn_config.get('password', ''),
                    database=conn_config['database'],
                    connect_timeout=2
                )
                conn.close()
                print(f"   âœ… {conn_type} è¿æ¥éªŒè¯æˆåŠŸ")
            except Exception as e:
                print(f"   âŒ {conn_type} è¿æ¥éªŒè¯å¤±è´¥: {e}")
                raise
    
    def _warmup_phase(self):
        """é¢„çƒ­é˜¶æ®µ"""
        print(f"\nğŸ”¥ é¢„çƒ­é˜¶æ®µ ({self.config.pgbench_config.warmup_time}ç§’)")
        print("-" * 20)
        
        # å¯åŠ¨è´Ÿè½½ç”Ÿæˆ
        self.load_generator.start_load_generation()
        
        # ç­‰å¾…é¢„çƒ­å®Œæˆ
        warmup_start = time.time()
        last_report_time = warmup_start
        
        while time.time() - warmup_start < self.config.pgbench_config.warmup_time:
            current_time = time.time()
            
            # æ¯10ç§’æŠ¥å‘Šä¸€æ¬¡é¢„çƒ­çŠ¶æ€
            if current_time - last_report_time >= 10:
                elapsed = int(current_time - warmup_start)
                remaining = self.config.pgbench_config.warmup_time - elapsed
                metrics = self.load_generator.get_current_metrics()
                
                print(f"   é¢„çƒ­ä¸­... {elapsed}s/{self.config.pgbench_config.warmup_time}s (å‰©ä½™ {remaining}s)")
                self._print_current_metrics(metrics, indent="     ")
                last_report_time = current_time
            
            time.sleep(1)
        
        print("âœ… é¢„çƒ­é˜¶æ®µå®Œæˆï¼Œå¼€å§‹æ­£å¼æµ‹è¯•")
    
    def _main_test_phase(self):
        """ä¸»æµ‹è¯•é˜¶æ®µ"""
        print(f"\nğŸš€ ä¸»æµ‹è¯•é˜¶æ®µ ({self.config.duration}ç§’)")
        print("-" * 20)
        print("ğŸ’¡ è¯·åœ¨å¦ä¸€ä¸ªç»ˆç«¯æ‰‹åŠ¨è§¦å‘æ•…éšœè½¬ç§»:")
        print("   aws rds failover-db-cluster --db-cluster-identifier ards-with-rdsproxy --region ap-southeast-1")
        print()
        
        self.test_running = True
        
        # å¯åŠ¨æ¯ç§è¿æ¥ç±»å‹çš„ç‹¬ç«‹downtimeç›‘æ§çº¿ç¨‹
        for conn_type in self.config.pgbench_config.connections.keys():
            monitor_thread = threading.Thread(
                target=self._monitor_connection_downtime,
                args=(conn_type,)
            )
            monitor_thread.daemon = True
            monitor_thread.start()
            self.monitor_threads[conn_type] = monitor_thread
        
        # ä¸»å¾ªç¯ï¼šç›‘æ§è´Ÿè½½æ€§èƒ½
        start_time = time.time()
        last_report_time = start_time
        
        while time.time() - start_time < self.config.duration:
            current_time = time.time()
            
            # æ¯5ç§’æŠ¥å‘Šä¸€æ¬¡æ€§èƒ½
            if current_time - last_report_time >= 5:
                metrics = self.load_generator.get_current_metrics()
                elapsed = int(current_time - start_time)
                remaining = self.config.duration - elapsed
                
                print(f"\nâ±ï¸  æµ‹è¯•è¿›è¡Œä¸­... ({elapsed}s/{self.config.duration}s, å‰©ä½™ {remaining}s)")
                self._print_current_metrics(metrics)
                
                # æ˜¾ç¤ºå½“å‰çš„downtimeçŠ¶æ€
                self._print_downtime_status()
                
                last_report_time = current_time
            
            time.sleep(1)
        
        self.test_running = False
        print("\nâœ… ä¸»æµ‹è¯•é˜¶æ®µå®Œæˆ")
    
    def _monitor_connection_downtime(self, conn_type: str):
        """ç›‘æ§ç‰¹å®šè¿æ¥ç±»å‹çš„downtime"""
        print(f"ğŸ” å¼€å§‹ç›‘æ§ {conn_type} è¿æ¥çš„downtime...")
        
        conn_config = self.config.pgbench_config.connections[conn_type]
        current_downtime = None
        check_interval = 0.1  # 100msæ£€æŸ¥é—´éš”
        
        while self.test_running:
            try:
                # å°è¯•è¿æ¥
                conn = psycopg2.connect(
                    host=conn_config['host'],
                    port=conn_config['port'],
                    user=conn_config['user'],
                    password=conn_config.get('password', ''),
                    database=conn_config['database'],
                    connect_timeout=1
                )
                
                # æ‰§è¡Œç®€å•æŸ¥è¯¢
                with conn.cursor() as cursor:
                    cursor.execute("SELECT 1")
                    cursor.fetchone()
                
                conn.close()
                
                # è¿æ¥æˆåŠŸ
                if current_downtime is not None:
                    # ç»“æŸå½“å‰çš„downtimeè®°å½•
                    current_downtime.finalize(datetime.now(timezone.utc))
                    self.downtime_records[conn_type].append(current_downtime)
                    print(f"   âœ… {conn_type} è¿æ¥æ¢å¤ï¼Œdowntime: {current_downtime.duration:.3f}ç§’")
                    current_downtime = None
                
            except Exception as e:
                # è¿æ¥å¤±è´¥
                if current_downtime is None:
                    # å¼€å§‹æ–°çš„downtimeè®°å½•
                    current_downtime = DowntimeRecord(
                        connection_type=conn_type,
                        start_time=datetime.now(timezone.utc)
                    )
                    print(f"   ğŸš¨ {conn_type} è¿æ¥å¤±è´¥ï¼Œå¼€å§‹è®°å½•downtime: {e}")
            
            time.sleep(check_interval)
        
        # æµ‹è¯•ç»“æŸæ—¶ï¼Œå¦‚æœè¿˜æœ‰æœªå®Œæˆçš„downtimeè®°å½•ï¼Œå®Œæˆå®ƒ
        if current_downtime is not None:
            current_downtime.finalize(datetime.now(timezone.utc))
            self.downtime_records[conn_type].append(current_downtime)
            print(f"   âš ï¸ æµ‹è¯•ç»“æŸæ—¶ {conn_type} ä»åœ¨downtimeï¼Œæ€»æ—¶é•¿: {current_downtime.duration:.3f}ç§’")
    
    def _print_current_metrics(self, metrics: dict, indent: str = "   "):
        """æ‰“å°å½“å‰æ€§èƒ½æŒ‡æ ‡"""
        for conn_type, data in metrics.items():
            if data['sample_count'] > 0:
                print(f"{indent}{conn_type:>6}: TPS={data['avg_tps']:>7.1f} "
                      f"(max:{data['max_tps']:>7.1f}), "
                      f"å»¶è¿Ÿ={data['avg_latency_ms']:>6.2f}ms "
                      f"(max:{data['max_latency_ms']:>6.2f}ms), "
                      f"é”™è¯¯={data['error_count']:>3d}")
            else:
                print(f"{indent}{conn_type:>6}: ç­‰å¾…æ•°æ®...")
    
    def _print_downtime_status(self):
        """æ‰“å°å½“å‰downtimeçŠ¶æ€"""
        for conn_type, records in self.downtime_records.items():
            if records:
                total_downtime = sum(record.duration for record in records if record.duration)
                active_downtime = len([r for r in records if r.end_time is None])
                print(f"   ğŸ“Š {conn_type} downtime: æ€»è®¡ {total_downtime:.3f}ç§’ "
                      f"({len(records)}æ¬¡ä¸­æ–­, {active_downtime}æ¬¡è¿›è¡Œä¸­)")
    
    def _analyze_results(self):
        """åˆ†æç»“æœ"""
        print("\nğŸ“Š ç»“æœåˆ†æ")
        print("-" * 20)
        
        # è·å–æœ€ç»ˆçš„è´Ÿè½½æŒ‡æ ‡
        final_metrics = self.load_generator.get_current_metrics()
        self.results['load_metrics'] = final_metrics
        
        # è·å–è¯¦ç»†æŒ‡æ ‡
        detailed_metrics = self.load_generator.get_detailed_metrics()
        self.results['detailed_metrics'] = detailed_metrics
        
        # æ•´ç†downtimeä¿¡æ¯
        self.results['downtime_analysis'] = self._analyze_downtime()
        
        # ç”ŸæˆæŠ¥å‘Š
        self._generate_report()
    
    def _analyze_downtime(self) -> Dict:
        """åˆ†ædowntimeæ•°æ®"""
        analysis = {}
        
        for conn_type, records in self.downtime_records.items():
            if records:
                durations = [r.duration for r in records if r.duration is not None]
                analysis[conn_type] = {
                    'total_downtime': sum(durations),
                    'downtime_count': len(records),
                    'avg_downtime': sum(durations) / len(durations) if durations else 0,
                    'max_downtime': max(durations) if durations else 0,
                    'min_downtime': min(durations) if durations else 0,
                    'records': [
                        {
                            'start': r.start_time.strftime('%H:%M:%S.%f')[:-3],
                            'end': r.end_time.strftime('%H:%M:%S.%f')[:-3] if r.end_time else 'N/A',
                            'duration': r.duration
                        }
                        for r in records
                    ]
                }
            else:
                analysis[conn_type] = {
                    'total_downtime': 0,
                    'downtime_count': 0,
                    'avg_downtime': 0,
                    'max_downtime': 0,
                    'min_downtime': 0,
                    'records': []
                }
        
        return analysis
    
    def _generate_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"results/pgbench_failover_report_{timestamp}.txt"
        
        print(f"ğŸ“„ ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š: {filename}")
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("Aurora PostgreSQL æ•…éšœè½¬ç§» + pgbench è´Ÿè½½æµ‹è¯•æŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            
            # æµ‹è¯•æ—¶é—´
            f.write(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            # æµ‹è¯•é…ç½®
            f.write("æµ‹è¯•é…ç½®:\n")
            f.write(f"  æµ‹è¯•æ—¶é•¿: {self.config.duration}ç§’\n")
            f.write(f"  pgbench å®¢æˆ·ç«¯æ•°: {self.config.pgbench_config.clients}\n")
            f.write(f"  pgbench ä½œä¸šæ•°: {self.config.pgbench_config.jobs}\n")
            f.write(f"  æ•°æ®è§„æ¨¡å› å­: {self.config.pgbench_config.scale_factor}\n")
            f.write(f"  æµ‹è¯•æ¨¡å¼: {self.config.pgbench_config.mode}\n")
            f.write(f"  é¢„çƒ­æ—¶é—´: {self.config.pgbench_config.warmup_time}ç§’\n\n")
            
            # è´Ÿè½½æ€§èƒ½ç»“æœ
            f.write("è´Ÿè½½æ€§èƒ½ç»“æœ:\n")
            for conn_type, metrics in self.results['load_metrics'].items():
                f.write(f"  {conn_type} è¿æ¥:\n")
                f.write(f"    å¹³å‡ TPS: {metrics['avg_tps']:.2f}\n")
                f.write(f"    æœ€å¤§ TPS: {metrics['max_tps']:.2f}\n")
                f.write(f"    æœ€å° TPS: {metrics['min_tps']:.2f}\n")
                f.write(f"    å¹³å‡å»¶è¿Ÿ: {metrics['avg_latency_ms']:.2f}ms\n")
                f.write(f"    æœ€å¤§å»¶è¿Ÿ: {metrics['max_latency_ms']:.2f}ms\n")
                f.write(f"    æœ€å°å»¶è¿Ÿ: {metrics['min_latency_ms']:.2f}ms\n")
                f.write(f"    é”™è¯¯æ•°é‡: {metrics['error_count']}\n")
                f.write(f"    é‡‡æ ·æ•°é‡: {metrics['sample_count']}\n\n")
            
            # è¯¦ç»†çš„downtimeåˆ†æ
            f.write("æ•…éšœè½¬ç§» Downtime åˆ†æ:\n")
            downtime_analysis = self.results['downtime_analysis']
            
            for conn_type, analysis in downtime_analysis.items():
                f.write(f"  {conn_type} è¿æ¥:\n")
                f.write(f"    æ€» downtime: {analysis['total_downtime']:.3f}ç§’\n")
                f.write(f"    ä¸­æ–­æ¬¡æ•°: {analysis['downtime_count']}\n")
                if analysis['downtime_count'] > 0:
                    f.write(f"    å¹³å‡ downtime: {analysis['avg_downtime']:.3f}ç§’\n")
                    f.write(f"    æœ€é•¿ downtime: {analysis['max_downtime']:.3f}ç§’\n")
                    f.write(f"    æœ€çŸ­ downtime: {analysis['min_downtime']:.3f}ç§’\n")
                    f.write("    è¯¦ç»†è®°å½•:\n")
                    for i, record in enumerate(analysis['records'], 1):
                        f.write(f"      #{i}: {record['start']} - {record['end']} "
                               f"({record['duration']:.3f}ç§’)\n")
                else:
                    f.write("    æ— ä¸­æ–­è®°å½•\n")
                f.write("\n")
            
            # å¯¹æ¯”åˆ†æ
            if len(downtime_analysis) == 2:
                f.write("Downtime å¯¹æ¯”åˆ†æ:\n")
                direct_downtime = downtime_analysis.get('direct', {}).get('total_downtime', 0)
                proxy_downtime = downtime_analysis.get('proxy', {}).get('total_downtime', 0)
                
                f.write(f"  Direct è¿æ¥æ€» downtime: {direct_downtime:.3f}ç§’\n")
                f.write(f"  Proxy è¿æ¥æ€» downtime: {proxy_downtime:.3f}ç§’\n")
                
                if direct_downtime > 0 and proxy_downtime > 0:
                    improvement = ((direct_downtime - proxy_downtime) / direct_downtime) * 100
                    f.write(f"  Proxy ç›¸å¯¹ Direct çš„æ”¹å–„: {improvement:+.1f}%\n")
                    
                    if improvement > 0:
                        f.write("  ç»“è®º: RDS Proxy åœ¨æ•…éšœè½¬ç§»æ—¶è¡¨ç°æ›´å¥½ï¼Œdowntime æ›´çŸ­\n")
                    else:
                        f.write("  ç»“è®º: Direct è¿æ¥åœ¨æ•…éšœè½¬ç§»æ—¶è¡¨ç°æ›´å¥½ï¼Œdowntime æ›´çŸ­\n")
                elif direct_downtime == 0 and proxy_downtime == 0:
                    f.write("  ç»“è®º: ä¸¤ç§è¿æ¥æ–¹å¼éƒ½æ²¡æœ‰æ£€æµ‹åˆ° downtime\n")
                elif direct_downtime == 0:
                    f.write("  ç»“è®º: Direct è¿æ¥æ²¡æœ‰ downtimeï¼ŒProxy è¿æ¥æœ‰ downtime\n")
                elif proxy_downtime == 0:
                    f.write("  ç»“è®º: Proxy è¿æ¥æ²¡æœ‰ downtimeï¼ŒDirect è¿æ¥æœ‰ downtime\n")
            
            # æ€§èƒ½å¯¹æ¯”ï¼ˆå¦‚æœæœ‰ä¸¤ç§è¿æ¥ç±»å‹ï¼‰
            if len(self.results['load_metrics']) == 2:
                f.write("\nè´Ÿè½½æ€§èƒ½å¯¹æ¯”åˆ†æ:\n")
                direct_metrics = self.results['load_metrics'].get('direct', {})
                proxy_metrics = self.results['load_metrics'].get('proxy', {})
                
                if direct_metrics and proxy_metrics:
                    tps_improvement = ((proxy_metrics['avg_tps'] - direct_metrics['avg_tps']) / direct_metrics['avg_tps']) * 100
                    latency_change = ((proxy_metrics['avg_latency_ms'] - direct_metrics['avg_latency_ms']) / direct_metrics['avg_latency_ms']) * 100
                    
                    f.write(f"  TPS å˜åŒ– (Proxy vs Direct): {tps_improvement:+.2f}%\n")
                    f.write(f"  å»¶è¿Ÿå˜åŒ– (Proxy vs Direct): {latency_change:+.2f}%\n")
        
        print(f"âœ… å¢å¼ºç‰ˆæµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {filename}")
        
        # åœ¨æ§åˆ¶å°æ˜¾ç¤ºç®€è¦ç»“æœ
        self._print_enhanced_summary()
    
    def _print_enhanced_summary(self):
        """æ‰“å°å¢å¼ºç‰ˆæµ‹è¯•æ‘˜è¦"""
        print("\nğŸ“‹ æµ‹è¯•æ‘˜è¦")
        print("-" * 30)
        
        # è´Ÿè½½æ€§èƒ½æ‘˜è¦
        for conn_type, metrics in self.results['load_metrics'].items():
            print(f"{conn_type} è¿æ¥:")
            print(f"  å¹³å‡ TPS: {metrics['avg_tps']:.2f}")
            print(f"  å¹³å‡å»¶è¿Ÿ: {metrics['avg_latency_ms']:.2f}ms")
            print(f"  é”™è¯¯æ•°é‡: {metrics['error_count']}")
        
        # Downtimeæ‘˜è¦
        print("\nDowntime æ‘˜è¦:")
        downtime_analysis = self.results['downtime_analysis']
        for conn_type, analysis in downtime_analysis.items():
            print(f"  {conn_type}: {analysis['total_downtime']:.3f}ç§’ "
                  f"({analysis['downtime_count']}æ¬¡ä¸­æ–­)")
    
    def _cleanup(self):
        """æ¸…ç†èµ„æº"""
        print("\nğŸ§¹ æ¸…ç†èµ„æº...")
        self.test_running = False
        self.load_generator.stop_load_generation()
        print("âœ… æ¸…ç†å®Œæˆ")
